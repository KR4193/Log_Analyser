{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "client = AzureOpenAI(\n",
    "  azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"), \n",
    "  api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),  \n",
    "  api_version=\"2024-02-01\"\n",
    ")\n",
    "log_file_path = \"C:/Users/kr4193/Desktop/Log_error_reporter/Prep_work/clean_Geiger_for_LLMs.log\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install sentence-transformers\n",
    "%pip install chromadb\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_docs(log_file_path):\n",
    "    with open(log_file_path, \"r\") as f:\n",
    "        logs = f.readlines()\n",
    "    return logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chunks(docs, chunk_size=5000,chunk_overlap = 50):\n",
    "    '''\n",
    "    given a list of documents, return a list of chunks of documents\n",
    "    '''\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    text = text_splitter.split_documents(docs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings_model(model_name = None, device  = None):\n",
    "    if model_name is None:\n",
    "        model_name = 'text-embedding-ada-002'\n",
    "    embeddings_model = HuggingFaceEmbeddings(model_name=model_name)\n",
    "    return embeddings_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vector_store(embeddings, texts, db_path, use_db = \"chroma\"):\n",
    "    flag = True\n",
    "    try:\n",
    "        if use_db == \"chroma\":\n",
    "            db = Chroma.from_documents(text, embeddings, persistent_directory = db_path)\n",
    "        else:\n",
    "            print(\"Unknowndb type\")\n",
    "        db.persist()\n",
    "    except:\n",
    "        flag = False\n",
    "    return flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_retriever():\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"text-embedding-ada-002\")\n",
    "    vectorDB = Chroma(persist_directory = DB_CHROMA_PATH,embedding_function = embeddings)\n",
    "    return vectorDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'HuggingFaceEmbeddings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m         output \u001b[38;5;241m=\u001b[39m chain\u001b[38;5;241m.\u001b[39minvoke(query)\n\u001b[0;32m     14\u001b[0m         \u001b[38;5;28mprint\u001b[39m(output)\n\u001b[1;32m---> 15\u001b[0m \u001b[43mqa_bot\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[11], line 2\u001b[0m, in \u001b[0;36mqa_bot\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mqa_bot\u001b[39m():\n\u001b[1;32m----> 2\u001b[0m     vectordb \u001b[38;5;241m=\u001b[39m \u001b[43mget_retriever\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m     retriever \u001b[38;5;241m=\u001b[39m vectordb\u001b[38;5;241m.\u001b[39mas_retriver(search_kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mk\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;241m10\u001b[39m})\n\u001b[0;32m      4\u001b[0m     chain \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m      5\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m\"\u001b[39m: retriever \u001b[38;5;241m|\u001b[39m format_docs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m:runnablePassthrough() }\n\u001b[0;32m      6\u001b[0m         \u001b[38;5;241m|\u001b[39m set_custom_prompt\n\u001b[0;32m      7\u001b[0m         \u001b[38;5;241m|\u001b[39m client\n\u001b[0;32m      8\u001b[0m     )\n",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m, in \u001b[0;36mget_retriever\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_retriever\u001b[39m():\n\u001b[1;32m----> 2\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mHuggingFaceEmbeddings\u001b[49m(model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext-embedding-ada-002\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m     vectorDB \u001b[38;5;241m=\u001b[39m Chroma(persist_directory \u001b[38;5;241m=\u001b[39m DB_CHROMA_PATH,embedding_function \u001b[38;5;241m=\u001b[39m embeddings)\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m vectorDB\n",
      "\u001b[1;31mNameError\u001b[0m: name 'HuggingFaceEmbeddings' is not defined"
     ]
    }
   ],
   "source": [
    "def qa_bot():\n",
    "    vectordb = get_retriever()\n",
    "    retriever = vectordb.as_retriver(search_kwargs = {\"k\":10})\n",
    "    chain = (\n",
    "        {\"context\": retriever | format_docs, \"question\":runnablePassthrough() }\n",
    "        | set_custom_prompt\n",
    "        | client\n",
    "    )\n",
    "\n",
    "    query = \"What is the error in the log file?\"\n",
    "    while query != \"quit\":\n",
    "        query = input(\"Enter your query: \")\n",
    "        output = chain.invoke(query)\n",
    "        print(output)\n",
    "qa_bot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
